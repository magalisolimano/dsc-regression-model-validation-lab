{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to validate your Ames Housing data model using a train-test split.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Perform a train-test split\n",
    "* Prepare training and testing data for modeling\n",
    "* Compare training and testing errors to determine if model is over or underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Use Our Ames Housing Data Again!\n",
    "\n",
    "We included the code to load the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                      \n",
       "1             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "3             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "4             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "5             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
       "Id                                    ...                                      \n",
       "1            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "2            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "3            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "4            Lvl    AllPub    Corner  ...        0    NaN    NaN         NaN   \n",
       "5            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
       "...          ...       ...       ...  ...      ...    ...    ...         ...   \n",
       "1456         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1457         Lvl    AllPub    Inside  ...        0    NaN  MnPrv         NaN   \n",
       "1458         Lvl    AllPub    Inside  ...        0    NaN  GdPrv        Shed   \n",
       "1459         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "1460         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
       "\n",
       "     MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                               \n",
       "1          0      2    2008        WD         Normal     208500  \n",
       "2          0      5    2007        WD         Normal     181500  \n",
       "3          0      9    2008        WD         Normal     223500  \n",
       "4          0      2    2006        WD        Abnorml     140000  \n",
       "5          0     12    2008        WD         Normal     250000  \n",
       "...      ...    ...     ...       ...            ...        ...  \n",
       "1456       0      8    2007        WD         Normal     175000  \n",
       "1457       0      2    2010        WD         Normal     210000  \n",
       "1458    2500      5    2010        WD         Normal     266500  \n",
       "1459       0      4    2010        WD         Normal     142125  \n",
       "1460       0      6    2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 80 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ames = pd.read_csv('ames.csv', index_col=0)\n",
    "ames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Train-Test Split\n",
    "\n",
    "Use `train_test_split` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)) with the default split size. At the end you should have `X_train`, `X_test`, `y_train`, and `y_test` variables, where `y` represents `SalePrice` and `X` represents all other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1095, 79), (365, 79), (1095,), (365,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here: split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = ames['SalePrice']\n",
    "X = ames.drop('SalePrice', axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)  #random state can be any number\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Both Sets for Modeling\n",
    "\n",
    "This code is completed for you and should work as long as the correct variables were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "\n",
    "continuous = ['LotArea', '1stFlrSF', 'GrLivArea']\n",
    "categoricals = ['BldgType', 'KitchenQual', 'Street']\n",
    "\n",
    "# Instantiate transformers\n",
    "log_transformer = FunctionTransformer(np.log, validate=True)\n",
    "ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "# Fit transformers\n",
    "log_transformer.fit(X_train[continuous])\n",
    "ohe.fit(X_train[categoricals])\n",
    "\n",
    "# Transform training data\n",
    "X_train = pd.concat([\n",
    "    pd.DataFrame(log_transformer.transform(X_train[continuous]), index=X_train.index),\n",
    "    pd.DataFrame(ohe.transform(X_train[categoricals]), index=X_train.index)\n",
    "], axis=1)\n",
    "\n",
    "# Transform test data\n",
    "X_test = pd.concat([\n",
    "    pd.DataFrame(log_transformer.transform(X_test[continuous]), index=X_test.index),\n",
    "    pd.DataFrame(ohe.transform(X_test[categoricals]), index=X_test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Linear Regression on the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: import the linear regression model class, initialize a model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here: fit the model to train data\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Validate Model\n",
    "\n",
    "### Generate Predictions on Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: generate predictions for both sets\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Mean Squared Error (MSE)\n",
    "\n",
    "You can use `mean_squared_error` from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: calculate training and test MSE\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your test error is substantially worse than the train error, this is a sign that the model doesn't generalize well to future cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squared Error:  1434846339.4615889\n",
      "Test Mean Squared Error:  2348945798.013306\n"
     ]
    }
   ],
   "source": [
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squared Error: ', train_mse)\n",
    "print('Test Mean Squared Error: ', test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple way to demonstrate overfitting and underfitting is to alter the size of our train-test split. By default, scikit-learn allocates 25% of the data to the test set and 75% to the training set. Fitting a model on only 10% of the data is apt to lead to underfitting, while training a model on 99% of the data is apt to lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up: Evaluate the Effect of Train-Test Split Size\n",
    "\n",
    "Iterate over a range of train-test split sizes from .5 to .9. For each of these, generate a new train/test split sample. Preprocess both sets of data. Fit a model to the training sample and calculate both the training error and the test error (MSE) for each of these splits. Plot these two curves (train error vs. training size and test error vs. training size) on a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_mses = []\n",
    "test_mses = []\n",
    "\n",
    "t_sizes = np.linspace(0.5, 0.9, 10)\n",
    "for t_size in t_sizes:\n",
    "    \n",
    "    #Create new split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=t_size, random_state=42)\n",
    "    \n",
    "    #Fit transformers on new train and test\n",
    "    log_transformer.fit(X_train[continuous])\n",
    "    ohe.fit(X_train[categoricals])\n",
    "    \n",
    "    #Transform training data\n",
    "    X_train = pd.concat([\n",
    "        pd.DataFrame(log_transformer.transform(X_train[continuous]), index=X_train.index),\n",
    "        pd.DataFrame(ohe.transform(X_train[categoricals]), index=X_train.index)\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Transform test data\n",
    "    X_test = pd.concat([\n",
    "        pd.DataFrame(log_transformer.transform(X_test[continuous]), index=X_test.index),\n",
    "        pd.DataFrame(ohe.transform(X_test[categoricals]), index=X_test.index)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Fit model\n",
    "    linreg.fit(X_train, y_train)\n",
    "    \n",
    "    # Append metrics to their respective lists\n",
    "    y_hat_train = linreg.predict(X_train)\n",
    "    y_hat_test = linreg.predict(X_test)\n",
    "    train_mses.append(mean_squared_error(y_train, y_hat_train))\n",
    "    test_mses.append(mean_squared_error(y_test, y_hat_test))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(t_sizes, train_mses, label='Training Error')\n",
    "ax.scatter(t_sizes, test_mses, label='Testing Error')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'RL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e25046666c8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 463\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'RL'"
     ]
    }
   ],
   "source": [
    "# other way\n",
    "\n",
    "train_error = []\n",
    "test_error = []\n",
    "\n",
    "for i in np.arange(0.05, 0.95, 0.05):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11, train_size = i)\n",
    "    linreg.fit(X_train, y_train)\n",
    "    train_error.append(mean_squared_error(y_train, linreg.predict(X_train)))\n",
    "    test_error.append(mean_squared_error(y_test, linreg.predict(X_test)))                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (18,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2b6a8391b807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fivethirtyeight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Training Error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Test Error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     return gca().plot(\n\u001b[1;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2795\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (18,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(np.arange(0.05, 0.95, 0.05), train_error, label = 'Training Error')\n",
    "plt.plot(np.arange(0.05, 0.95, 0.05), test_error, label = 'Test Error')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension\n",
    "\n",
    "Repeat the previous example, but for each train-test split size, generate 10 iterations of models/errors and save the average train/test error. This will help account for any particularly good/bad models that might have resulted from poor/good splits in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "train_mses = []\n",
    "test_mses = []\n",
    "\n",
    "t_sizes = np.linspace(0.5, 0.9, 10)\n",
    "for t_size in t_sizes:\n",
    "    \n",
    "    inner_train_mses = []\n",
    "    inner_test_mses = []\n",
    "    for i in range(10):\n",
    "        # Create new split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size, random_state=i)\n",
    "        \n",
    "        # Skipping fitting the transformers; data quality issues cause too many OHE problems when\n",
    "        # fitting this number of different models, but if you don't use drop='first' the\n",
    "        # multicollinearity issues get pretty bad\n",
    "\n",
    "        # Transform training data\n",
    "        X_train = pd.concat([\n",
    "            pd.DataFrame(log_transformer.transform(X_train[continuous]), index=X_train.index),\n",
    "            pd.DataFrame(ohe.transform(X_train[categoricals]), index=X_train.index)\n",
    "        ], axis=1)\n",
    "\n",
    "        # Transform test data\n",
    "        X_test = pd.concat([\n",
    "            pd.DataFrame(log_transformer.transform(X_test[continuous]), index=X_test.index),\n",
    "            pd.DataFrame(ohe.transform(X_test[categoricals]), index=X_test.index)\n",
    "        ], axis=1)\n",
    "\n",
    "        # Fit model\n",
    "        linreg.fit(X_train, y_train)\n",
    "\n",
    "        # Append metrics to their respective lists\n",
    "        y_hat_train = linreg.predict(X_train)\n",
    "        y_hat_test = linreg.predict(X_test)\n",
    "        inner_train_mses.append(mean_squared_error(y_train, y_hat_train))\n",
    "        inner_test_mses.append(mean_squared_error(y_test, y_hat_test))\n",
    "\n",
    "    train_mses.append(np.mean(inner_train_mses))\n",
    "    test_mses.append(np.mean(inner_test_mses))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(t_sizes, train_mses, label='Average Training Error')\n",
    "ax.scatter(t_sizes, test_mses, label='Average Testing Error')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here? Evaluate your result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now practiced your knowledge of MSE and used your train-test split skills to validate your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
